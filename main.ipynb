{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error, mean_squared_error, mean_absolute_error, confusion_matrix, accuracy_score, jaccard_score, f1_score, roc_curve, auc\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor, LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Armar un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('weatherAUS.csv')\n",
    "df_subset = df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vistazo rapido del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ver las columnas e identificar cada una"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25 Columnas\n",
    "\n",
    "**Unnamed** Indices (no esta en df_subset)\n",
    "\n",
    "**Date** fecha de la observacion\n",
    "\n",
    "**Location** Nombre del lugar donde esta la estacion meteorologica\n",
    "\n",
    "**MinTemp** Temperatura minima. En grados celsius\n",
    "\n",
    "**MaxTemp** Temperatura maxima. En grados celsius\n",
    "\n",
    "**Rainfall** cantidad de lluvia registrada en el dia. En mm\n",
    "\n",
    "**Evaporation** evaporacion (mm) de 00 a 09am.\n",
    "\n",
    "**Sunshine** Numero de horas de luz solar durante el dia.\n",
    "\n",
    "**WindGustDir** direccion de la rafaga de viento mas fuerte en las 24 horas\n",
    "\n",
    "**WindGustSpeed** velocidad de la rafaga de viento mas fuerte en km/h\n",
    "\n",
    "**WindDir9am** direccion del viento a las 9 am\n",
    "\n",
    "**WindDir3pm** direccion del viento a las 3 pm\n",
    "\n",
    "**WindSpeed9am** velocidad del viento en km/h, a las 9 am\n",
    "\n",
    "**WindSpeed3pm** velocidad del viento en km/h, a las 3 pm\n",
    "\n",
    "**Humidity9am** humedad en porcentaje a las 9 am\n",
    "\n",
    "**Humidity3pm** humedad en porcentaje a las 3 pm\n",
    "\n",
    "**Pressure9am** presion atmosferica en (hpa) al nivel del mar a las 9 am\n",
    "\n",
    "**Pressure9am** presion atmosferica en (hpa) al nivel del mar a las 3 pm\n",
    "\n",
    "**Cloud9am** Fraccion del cielo oscurecida por nubes medida en fracciones de 8 (0 indica sin nubes, 8 totalmente nublado) a las 9 am\n",
    "\n",
    "**Cloud9am** Fraccion del cielo oscurecida por nubes medida en fracciones de 8 (0 indica sin nubes, 8 totalmente nublado) a las 3pm\n",
    "\n",
    "**Temp9am** temperatura en grados celsius a las 9 am\n",
    "\n",
    "**Temp3pm** temperatura en grados celsius a las 3 pm\n",
    "\n",
    "**RainToday** valor booleano si llovio o no durante el dia (1 si pasa 1 mm)\n",
    "\n",
    "**RainTomorrow** Cantidad de lluvia al dia siguiente en mm\n",
    "\n",
    "**RainfallTomorrow** cantidad de lluvia al dia siguiente en mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Que no voy a usar\n",
    "Date No se va a usar\n",
    "Localization sera descartada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df_subset.drop(['Date'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# codear localizacion para costa este solamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_replace= [\"Sydney\", \"SydneyAirport\", \"Canberra\",\"Melbourne\", \"MelbourneAirport\"]\n",
    "df_subset['Location'] = df_subset['Location'].replace(locations_replace, 'East Coast')\n",
    "\n",
    "\n",
    "filtered_df = df_subset[df_subset['Location'] == 'East Coast']\n",
    "\n",
    "\n",
    "filtered_df = filtered_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filtered_df.drop(['Location'], axis=1)\n",
    "filtered_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Que valores son numericos y cuales son categoricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_or_cat(df):\n",
    "    categorical = df.select_dtypes(include='object').columns\n",
    "    numerical = df.select_dtypes(exclude='object').columns\n",
    "\n",
    "    return(categorical, numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols, numerical_cols= num_or_cat(filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols_graph = categorical_cols.delete(0)\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(numerical_cols)):\n",
    "    plt.figure(figsize=(3,3))\n",
    "    sns.histplot(filtered_df[numerical_cols[i]], color=\"blue\")\n",
    "    label=numerical_cols[i]\n",
    "    plt.xlabel(numerical_cols[i])\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.title(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contando valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# llenar columnas numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputerResto = KNNImputer(missing_values=np.nan, n_neighbors=2)\n",
    "\n",
    "for columna in numerical_cols:\n",
    "   filtered_df[columna] = imputerResto.fit_transform(filtered_df[[columna]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capaz saque rainfall tomorrow del loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cambiar Datos categoricos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de las columnas RainToday y RainTomorrow pasar Yes a 1 y no a 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['RainToday']=filtered_df['RainToday'].fillna('No')\n",
    "filtered_df['RainTomorrow']=filtered_df['RainTomorrow'].fillna('No')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# El resto de columnas categoricas reemplazar valores faltantes por la moda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['WindGustDir'] = filtered_df['WindGustDir'].fillna(filtered_df['WindGustDir'].mode()[0])\n",
    "filtered_df['WindDir9am'] = filtered_df['WindDir9am'].fillna(filtered_df['WindDir9am'].mode()[0])\n",
    "filtered_df['WindDir3pm'] = filtered_df['WindDir3pm'].fillna(filtered_df['WindDir3pm'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graficar datos numericos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(numerical_cols)):\n",
    "    plt.figure(figsize=(3,3))\n",
    "    sns.histplot(filtered_df[numerical_cols[i]], color=\"blue\")\n",
    "    label=numerical_cols[i]\n",
    "    plt.xlabel(numerical_cols[i])\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.title(label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graficar Categoricos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(categorical_cols_graph)):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    sns.histplot(filtered_df[categorical_cols_graph[i]], color=\"blue\")\n",
    "    label=categorical_cols_graph[i]\n",
    "    plt.xlabel(categorical_cols_graph[i])\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.title(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check si esta balanceado\n",
    "\n",
    "no esta balanceado (por mas que ya haya reemplazado lso valores faltantes sigue estando desbalanceado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3,3))\n",
    "sns.countplot(x=df_subset['RainTomorrow'])\n",
    "plt.title(\"Balanceado\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copia_df = filtered_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codear los datos categoricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "for columna in categorical_cols:\n",
    "    copia_df[columna] = le.fit_transform(copia_df[columna])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacer matriz de correlacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(copia_df.corr(),annot=True, cmap=\"Blues\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividir en train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copia_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = copia_df.iloc[:,:-2].values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = copia_df['RainfallTomorrow'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crear los modelos de regression lasso ridge elasticnet y gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=0.1)\n",
    "ridge = Ridge(alpha=0.1)  \n",
    "elasticnet = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "grad = SGDRegressor(max_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grad.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squared = r2_score(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test,y_pred)\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "print(\"R2:\", r_squared)\n",
    "print(\"Mean Abs Precentage error:\", mape)\n",
    "print(\"Mean Sq Error\", mse)\n",
    "print(\"Mean Abs Error\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresion Logistica usando (Rain tomorrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copia_df_log = copia_df.drop(['RainfallTomorrow'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_log = copia_df_log.iloc[:,:-1].values\n",
    "y_log = copia_df_log['RainTomorrow']\n",
    "X_train_log,X_test_log,y_train_log,y_test_log = train_test_split(X_log,y_log,test_size=0.25,random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler_log=MinMaxScaler()\n",
    "X_train_log=scaler_log.fit_transform(X_train_log)\n",
    "X_test_log=scaler_log.transform(X_test_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crear modelo de reg logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_log = LogisticRegression(random_state = 0)\n",
    "reg_log.fit(X_train_log, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = reg_log.predict(X_test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test_log, predictions)\n",
    "\n",
    "LR_Accuracy_Score = accuracy_score(y_test_log, predictions)\n",
    "\n",
    "\n",
    "LR_JaccardIndex = jaccard_score(y_test_log, predictions, average='weighted')\n",
    "\n",
    "\n",
    "LR_F1_Score = f1_score(y_test_log, predictions, average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(cm)\n",
    "print(\"reg_log Accuracy:\", LR_Accuracy_Score)\n",
    "print(\"reg_log Jaccard Index:\", LR_JaccardIndex)\n",
    "print(\"reg_log F1:\", LR_F1_Score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test_log, predictions)\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'AUC = {roc_auc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\n",
    "plt.xlabel('Valores False Positive ')\n",
    "plt.ylabel('Valores True positive')\n",
    "plt.title('ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 5 crear modelos base de regresion y clasificacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copia_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_base_reg = copia_df[['Rainfall','Humidity3pm']].values\n",
    "y_base_reg = copia_df[['RainfallTomorrow']].values\n",
    "#######         ##########\n",
    "X_train_base_reg, X_test_base_reg, y_train_base_reg, y_test_base_reg = train_test_split(X_base_reg, y_base_reg, test_size=0.1)\n",
    "#######         ##########\n",
    "X_base_clas = copia_df[['Cloud3pm','WindDir9am']]\n",
    "y_base_clas = copia_df[['RainTomorrow']]\n",
    "#######         ##########\n",
    "X_train_base_clas, X_test_base_clas, y_train_base_clas, y_test_base_clas = train_test_split(X_base_clas, y_base_clas, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train_base_reg, y_train_base_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_base_reg = regressor.predict(X_test_base_reg)\n",
    "\n",
    "r_cuad = r2_score(y_test_base_reg, y_pred_base_reg)\n",
    "print(f\"R^2 score: {r_cuad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificator = LogisticRegression()\n",
    "classificator.fit(X_train_base_clas, y_train_base_clas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_base_clas = classificator.predict(X_test_base_clas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test_base_clas, y_pred_base_clas)\n",
    "print(f\"Precision del modelo de regresion logistica base: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 6 Entrenar una red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import optuna\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.layers import Input, Dense\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ann = copia_df.iloc[:,:-1].values\n",
    "y_ann = copia_df['RainTomorrow'].values\n",
    "X_train_ann,X_test_ann,y_train_ann,y_test_ann = train_test_split(X_ann,y_ann,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "X_train, X_test_ann, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42) # necesitamos un conjunto de validación para obtener hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-16 20:52:56,537] A new study created in memory with name: no-name-8685465d-fab4-41bf-913d-8668fa346003\n",
      "[I 2023-11-16 20:53:28,314] Trial 0 finished with value: 0.7714196443557739 and parameters: {'learning_rate': 0.005551347957030787, 'num_layers': 3, 'activation_layer_0': 'sigmoid', 'n_units_layer_0': 18, 'activation_layer_1': 'sigmoid', 'n_units_layer_1': 20, 'activation_layer_2': 'tanh', 'n_units_layer_2': 93}. Best is trial 0 with value: 0.7714196443557739.\n",
      "[I 2023-11-16 20:54:06,535] Trial 1 finished with value: 0.7714196443557739 and parameters: {'learning_rate': 0.0036941394123863433, 'num_layers': 3, 'activation_layer_0': 'relu', 'n_units_layer_0': 93, 'activation_layer_1': 'tanh', 'n_units_layer_1': 39, 'activation_layer_2': 'tanh', 'n_units_layer_2': 122}. Best is trial 0 with value: 0.7714196443557739.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parámetros encontrados: {'learning_rate': 0.005551347957030787, 'num_layers': 3, 'activation_layer_0': 'sigmoid', 'n_units_layer_0': 18, 'activation_layer_1': 'sigmoid', 'n_units_layer_1': 20, 'activation_layer_2': 'tanh', 'n_units_layer_2': 93}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    lr = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        # Sugerir activaciones\n",
    "        activation = trial.suggest_categorical(f'activation_layer_{i}', ['relu', 'sigmoid', 'tanh'])\n",
    "        num_units = trial.suggest_int(f'n_units_layer_{i}', 4, 128)\n",
    "        ann.add(Dense(num_units, activation=activation))\n",
    "\n",
    "    # capa de salida\n",
    "    ann.add(Dense(1, activation='sigmoid')) #la clase de salida\n",
    "\n",
    "    # compilar\n",
    "    ann.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # entrenar\n",
    "    ann.fit(X_train_ann, y_train_ann, validation_data=(X_test_ann, y_test_ann), epochs=5, batch_size=32, verbose=0)\n",
    "\n",
    "    # evaluar\n",
    "    score = ann.evaluate(X_test_ann, y_test_ann, verbose=0)\n",
    "    return score[1]\n",
    "\n",
    "# crear un estudio de Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=2)\n",
    "\n",
    "# obtener los mejores hiperparámetros\n",
    "best_params = study.best_params\n",
    "print(\"Best parámetros encontrados:\", best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
